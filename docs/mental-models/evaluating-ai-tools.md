# Evaluating AI Development Tools

**Understanding the spectrum from conversational AI to local agents**

## Summary

Not all AI tools are the same. Understanding what tier a tool operates at helps you choose the right tool for the task and manage risk appropriately.

### The Three-Tier Model

| Tier | Description | Examples |
|------|-------------|----------|
| **Tier 1: Conversational** | Text in/text out, no execution | ChatGPT web, Claude.ai |
| **Tier 2: Remote Sandbox** | Executes in isolated cloud environment | Code Interpreter, AI Studio |
| **Tier 3: Local Agent** | Executes on your actual machine | Claude Code CLI, Cursor |

### Key Principles

- **Capabilities increase with tier** — And so do trust requirements
- **Match tier to task** — Understanding needs less access than building
- **Security scales with access** — More power means more caution required
- **Evaluate systematically** — Ask what permissions a tool needs and why

### Choosing the Right Tier

- **"I need to understand something"** → Tier 1 is sufficient
- **"I need to test/prototype in isolation"** → Tier 2 is ideal
- **"I need to build/modify my actual project"** → Tier 3 is most efficient
- **"I'm working with sensitive data"** → Start at Tier 1, escalate carefully

---

*This GitHub copy is a summary. The full guide lives on the [docs site](https://dev.episkopos.community/docs/mental-models/evaluating-ai-tools).*
